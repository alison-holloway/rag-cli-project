# RAG CLI Configuration
# Copy this file to .env and customize as needed

# =============================================================================
# LLM Configuration
# =============================================================================

# Ollama settings (FREE - local LLM, default)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Claude API settings (OPTIONAL - uncomment if using --llm claude)
# ANTHROPIC_API_KEY=your_api_key_here

# Default LLM provider: "ollama" (free) or "claude" (paid)
DEFAULT_LLM_PROVIDER=ollama

# LLM generation parameters
LLM_TEMPERATURE=0.3
MAX_TOKENS=2000

# =============================================================================
# Vector Store Configuration
# =============================================================================

# Directory for ChromaDB persistence
CHROMA_PERSIST_DIR=./data/vector_db

# =============================================================================
# Embedding Configuration
# =============================================================================

# Embedding model (sentence-transformers)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# =============================================================================
# Document Processing Configuration
# =============================================================================

# Text chunking parameters
CHUNK_SIZE=1200
CHUNK_OVERLAP=200

# =============================================================================
# Retrieval Configuration
# =============================================================================

# Number of chunks to retrieve for context
TOP_K_RESULTS=5

# =============================================================================
# Logging Configuration
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (leave empty to disable file logging)
LOG_FILE=./logs/rag-cli.log
